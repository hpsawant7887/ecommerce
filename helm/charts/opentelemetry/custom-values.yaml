mode: daemonset

service:
  enabled: true
  
ports:
  metrics:
    enabled: true
    containerPort: 9090
    servicePort: 9090
    protocol: TCP

image:
  repository: otel/opentelemetry-collector-contrib

presets:
  # enables the k8sattributesprocessor and adds it to the traces, metrics, and logs pipelines
  kubernetesAttributes:
    enabled: true
  # enables the kubeletstatsreceiver and adds it to the metrics pipelines
  kubeletMetrics:
    enabled: true
  # Enables the filelogreceiver and adds it to the logs pipelines
  logsCollection:
    enabled: true

config:
  receivers:
    otlp:
      protocols:
        grpc:
          endpoint: 0.0.0.0:4317
        http:
          endpoint: 0.0.0.0:4318
    prometheus:
      config:
        scrape_configs:
        - job_name: 'users-service-flask-app'
          scrape_interval: 10s
          static_configs:
          - targets: ['demo-eshop-users-service.users-service.svc.cluster.local:8080']
        - job_name: 'onlinestore-service-flask-app'
          scrape_interval: 10s
          static_configs:
          - targets: ['demo-eshop-onlinestore-service.onlinestore-service.svc.cluster.local:8081']
        - job_name: 'ordering-service-flask-app'
          scrape_interval: 10s
          static_configs:
          - targets: ['demo-eshop-ordering-service.ordering-service.svc.cluster.local:8083']
        - job_name: 'carts-service-flask-app'
          scrape_interval: 10s
          static_configs:
          - targets: ['demo-eshop-carts-service.carts-service.svc.cluster.local:8082']
        - job_name: 'shipping-service-flask-app'
          scrape_interval: 10s
          static_configs:
          - targets: ['demo-eshop-shipping-service.shipping-service.svc.cluster.local:8084']
          
    filelog:
      include:
        - /var/log/pods/*/*/*.log
      start_at: beginning
      include_file_path: true
      include_file_name: false
      operators:
        # Find out which format is used by kubernetes
        - type: router
          id: get-format
          routes:
            # - output: parser-docker
            #   expr: 'body matches "^\\{"'
            # - output: parser-crio
            #   expr: 'body matches "^[^ Z]+ "'
            - output: parser-containerd
              expr: 'body matches "^[^ Z]+Z"'
        # Parse CRI-O format
        # - type: regex_parser
        #   id: parser-crio
        #   regex: '^(?P<time>[^ Z]+) (?P<stream>stdout|stderr) (?P<logtag>[^ ]*) ?(?P<log>.*)$'
        #   output: extract_metadata_from_filepath
        #   timestamp:
        #     parse_from: attributes.time
        #     layout_type: gotime
        #     layout: '2006-01-02T15:04:05.999999999Z07:00'
        # Parse CRI-Containerd format
        - type: regex_parser
          id: parser-containerd
          regex: '^(?P<time>[^ ^Z]+Z) (?P<stream>stdout|stderr) (?P<logtag>[^ ]*) ?(?P<log>.*)$'
          output: extract_metadata_from_filepath
          timestamp:
            parse_from: attributes.time
            layout: '%Y-%m-%dT%H:%M:%S.%LZ'
        # Parse Docker format
        # - type: json_parser
        #   id: parser-docker
        #   output: extract_metadata_from_filepath
        #   timestamp:
        #     parse_from: attributes.time
        #     layout: '%Y-%m-%dT%H:%M:%S.%LZ'
        # Extract metadata from file path
        - type: regex_parser
          id: extract_metadata_from_filepath
          # Pod UID is not always 36 characters long
          regex: '^.*\/(?P<namespace>[^_]+)_(?P<pod_name>[^_]+)_(?P<uid>[a-f0-9\-]{16,36})\/(?P<container_name>[^\._]+)\/(?P<restart_count>\d+)\.log$'
          parse_from: attributes["log.file.path"]
          cache:
            size: 128 # default maximum amount of Pods per Node is 110
        # Rename attributes
        - type: move
          from: attributes["log.file.path"]
          to: resource["filename"]
        - type: move
          from: attributes.container_name
          to: resource["container"]
        - type: move
          from: attributes.namespace
          to: resource["namespace"]
        - type: move
          from: attributes.pod_name
          to: resource["pod"]
        - type: add
          field: resource["cluster"]
          value: 'demo-eshop-eks-cluster' # Set your cluster name here
        - type: move
          from: attributes.log
          to: body
  processors:
    batch:
      send_batch_size: 1000
      timeout: 5s
    resource:
      attributes:
        - action: insert
          key: loki.format
          value: raw
        - action: insert
          key: loki.resource.labels
          value: pod,namespace,container,cluster,filename
  exporters:
    logging:
      verbosity: detailed
    prometheus:
      endpoint: "0.0.0.0:9090"
    # prometheus/B:
    #   endpoint: "localhost:9090"
    otlphttp/loki:
      endpoint: http://ecomm-grafana-loki-gateway.observability.svc.cluster.local/otlp
    loki: 
      endpoint: http://ecomm-grafana-loki-gateway.observability.svc.cluster.local/loki/api/v1/push 
    otlp/A:
      endpoint: api.honeycomb.io:443
      headers:
        x-honeycomb-team: hcaik_01j737pkpnce9x3ndwkrag11qc0h5s4vtv4ngtemab4mjbyejz13spjbbf
    # otlp/B:
    #   endpoint: "0.0.0.0:4317"
    
  service:
    pipelines:
      logs:
        receivers: [filelog, otlp]
        processors: [batch, resource]
        exporters: [loki]
      metrics:
        receivers: [otlp, prometheus]
        processors: [batch]
        exporters: [prometheus, debug]
      traces:
        receivers: [otlp]
        processors: [batch]
        exporters: [otlp/A, debug]


    

      



